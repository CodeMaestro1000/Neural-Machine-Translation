{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Machine Translation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrGdLot3co75"
      },
      "source": [
        "# Introduction\n",
        "In this colab, we're going to make use of Neural Machine Translation and Bahdanau and Luong's attention mechanism to build a language translator for text data.\n",
        "\n",
        "Most of the code in this colab is already available as a tensorflow example. See example at:\n",
        "\n",
        "https://www.tensorflow.org/tutorials/text/nmt_with_attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iRd6eZrdJPI",
        "outputId": "19954300-b210-4ac3-9ef6-b32a8977eced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVDIURfEdt8p",
        "outputId": "9aaff2ca-e5a3-4fa9-feb8-23dc30bb3469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# unzip file\n",
        "! unzip '/content/drive/My Drive/deu-eng.zip' -d '/content/drive/My Drive/deu-eng'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/deu-eng.zip\n",
            "  inflating: /content/drive/My Drive/deu-eng/deu.txt  \n",
            "  inflating: /content/drive/My Drive/deu-eng/_about.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EddySp42euEZ"
      },
      "source": [
        "# import modules and APIs\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWFC1V-PdEID"
      },
      "source": [
        "# Data Preparation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DOqwdF_fbZm"
      },
      "source": [
        "In the next steps, we have to create functions that will: \n",
        "\n",
        "*   Convert the data from unicode to ascii\n",
        "*   Add a start and end token to each sentence.\n",
        "*   Clean the sentences by removing special characters.\n",
        "*   Okenize the data to create word tokens and pad necessary tokens.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR9gCguHgSYb"
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm2RKtobghsE"
      },
      "source": [
        "Next, we'll create a function that puts all the pre-processing together and returns the sentances as source-target pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ4FWspFgb3o"
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, GERMAN ]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:-1]]  for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_B1Z0tPhZ9q"
      },
      "source": [
        "Finally, we'll tokenize the sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnAQD3MihX02"
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer\n",
        "\n",
        "# Function slightly modified to return input before target\n",
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  inp_lang, targ_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5IN1nPKiByM"
      },
      "source": [
        "Beforewe continue, let's take a look at how our raw data looks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyeqL9utiIpp",
        "outputId": "139dff7a-b191-4288-dc13-fbe18e9742de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "file_path = r'/content/drive/My Drive/deu-eng/deu.txt'\n",
        "ct = 0\n",
        "with open(file_path, \"r\") as dfile:\n",
        "  for line in dfile:\n",
        "    print(line)\n",
        "    ct += 1\n",
        "    if ct > 4:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go.\tGeh.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)\n",
            "\n",
            "Hi.\tHallo!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)\n",
            "\n",
            "Hi.\tGrüß Gott!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)\n",
            "\n",
            "Run!\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)\n",
            "\n",
            "Run.\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #941078 (Fingerhut)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYP5EppqjTQV"
      },
      "source": [
        "As we can see here, it seems like some of the lines of the file are duplicates. However, it seems like duplicates should not affect our performance.\n",
        "\n",
        "Let's apply the pre-processig now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOr7DZttkDN8"
      },
      "source": [
        "dfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgp16RI4kGPf",
        "outputId": "6db8dacc-9f2a-4d5d-eb93-f30c590e2957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "en, de = create_dataset(file_path, None)\n",
        "print(en[-1])\n",
        "print(de[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<start> go . <end>', '<start> geh . <end>']\n",
            "<start> doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman . <end>\n",
            "<start> ohne zweifel findet sich auf dieser welt zu jedem mann genau die richtige ehefrau und umgekehrt wenn man jedoch in betracht zieht , dass ein mensch nur gelegenheit hat , mit ein paar hundert anderen bekannt zu sein , von denen ihm nur ein dutzend oder weniger nahesteht , darunter hochstens ein oder zwei freunde , dann erahnt man eingedenk der millionen einwohner dieser welt leicht , dass seit erschaffung ebenderselben wohl noch nie der richtige mann der richtigen frau begegnet ist . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8twr1NJTn9I-"
      },
      "source": [
        "Our dataset contains more than 200,000 examples. Let's make use of 100,000 examples (to enhance training time)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxPZLQ5-n59U"
      },
      "source": [
        "num_examples = 100000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(file_path, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9wmwX0DobPJ",
        "outputId": "f33b6553-47d2-46f8-e460-985b5cd1482e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Max input length: {}'.format(max_length_targ))\n",
        "print('Max output length: {}'.format(max_length_inp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max input length: 22\n",
            "Max output length: 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwISnnq0ovE2",
        "outputId": "02fe8246-1702-43db-cc96-3be7fd75a5e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "X_train, X_val, y_train, y_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(X_train), len(y_train), len(X_val), len(y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80000 80000 20000 20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzDYoY4FpJhD"
      },
      "source": [
        "# Function displays the word index in tensor\n",
        "# Word index is created by tokenizer.\n",
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-svfLaEpdsH",
        "outputId": "534e49c4-a391-47e8-83cc-7a5197b007dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, X_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "53 ----> why\n",
            "65 ----> didn\n",
            "11 ----> t\n",
            "6 ----> you\n",
            "123 ----> say\n",
            "787 ----> goodbye\n",
            "7 ----> ?\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "56 ----> warum\n",
            "35 ----> haben\n",
            "10 ----> sie\n",
            "9 ----> nicht\n",
            "30 ----> auf\n",
            "957 ----> wiedersehen\n",
            "134 ----> gesagt\n",
            "6 ----> ?\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhy-65DAqv5d"
      },
      "source": [
        "# Create TF dataset\n",
        "BUFFER_SIZE = len(X_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(X_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pM_fqIVrD7Y",
        "outputId": "def3657e-80d8-4db4-cf09-ee6fe63e4413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 12]), TensorShape([64, 22]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUtqCj_mrH0l"
      },
      "source": [
        "# Encoder and Decoder Model.\n",
        "\n",
        "The encoder model maps the input data to a vector called the context vector. Thus encoding maps the *meaning* of the input sentence into a vector.\n",
        "\n",
        "The encoder model also contains an attention layer which we'll see later. This layer makes use of attention weights to give more attention to specific words in the input sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW3bMQEgrHUG"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHPsC9tOs5kX"
      },
      "source": [
        "The Encoder class returns an output along with the hidden-state vector (or context vector).\n",
        "\n",
        "The attention layer takes the encoder output, the encoder hidden-state to compute the attention weights.\n",
        "\n",
        "With these weights, the context vector is computed and with the context vector along with the a tanh activation function, the attention vector is produced.\n",
        "\n",
        "See equations:\n",
        "https://www.tensorflow.org/tutorials/text/nmt_with_attention#write_the_encoder_and_decoder_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvgSubEmtvlf"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZrjzEl7t2vE"
      },
      "source": [
        "The attention vector returns the attention weights and context vector and is used in the Decoder Model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcKYOcoouPb7"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YygUatndugjR"
      },
      "source": [
        "The decoder treats the output as a set of Logits and returns the id (of word index) with the maximum logit value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6ZQYM1nuZCy"
      },
      "source": [
        "# Define the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPHjMLT_uShA"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBGSdNzbvBb9"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "attention_layer = BahdanauAttention(10)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui_XrXFSux5r"
      },
      "source": [
        "# Checkpoints (Object-based saving)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDd6V8ghufFw"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJiL6V0SvLST"
      },
      "source": [
        "# Training\n",
        "\n",
        "*   The input is fed to the encoder to get encoder output and hidden states.\n",
        "*   The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n",
        "\n",
        "* The decoder returns the predictions and the decoder hidden state.\n",
        "\n",
        "* The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
        "\n",
        "* Teacher forcing is then to decide the next input to the decoder.\n",
        "\n",
        "**Note: Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n",
        "Concretely, Teacher forcing is like a teacher correcting a student as the student gets trained on a new concept. As the right input is given by the teacher to the student during training, student will learn the new concept faster and efficiently.**\n",
        "\n",
        "* The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiHRMRcPvK8N"
      },
      "source": [
        "@tf.function # Static method\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80bgs72nwITv",
        "outputId": "4d0d1f6c-1c4d-4b8b-ebaf-db3eab1ee992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.8551\n",
            "Epoch 1 Batch 100 Loss 1.4611\n",
            "Epoch 1 Batch 200 Loss 1.3388\n",
            "Epoch 1 Batch 300 Loss 1.1714\n",
            "Epoch 1 Batch 400 Loss 1.2058\n",
            "Epoch 1 Batch 500 Loss 1.0720\n",
            "Epoch 1 Batch 600 Loss 1.1028\n",
            "Epoch 1 Batch 700 Loss 1.0320\n",
            "Epoch 1 Batch 800 Loss 1.0067\n",
            "Epoch 1 Batch 900 Loss 1.0181\n",
            "Epoch 1 Batch 1000 Loss 0.9604\n",
            "Epoch 1 Batch 1100 Loss 1.0310\n",
            "Epoch 1 Batch 1200 Loss 0.8781\n",
            "Epoch 1 Loss 1.1449\n",
            "Time taken for 1 epoch 192.10087990760803 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.7907\n",
            "Epoch 2 Batch 100 Loss 0.7874\n",
            "Epoch 2 Batch 200 Loss 0.7972\n",
            "Epoch 2 Batch 300 Loss 0.7278\n",
            "Epoch 2 Batch 400 Loss 0.7413\n",
            "Epoch 2 Batch 500 Loss 0.6391\n",
            "Epoch 2 Batch 600 Loss 0.6511\n",
            "Epoch 2 Batch 700 Loss 0.7084\n",
            "Epoch 2 Batch 800 Loss 0.5753\n",
            "Epoch 2 Batch 900 Loss 0.5969\n",
            "Epoch 2 Batch 1000 Loss 0.5414\n",
            "Epoch 2 Batch 1100 Loss 0.5337\n",
            "Epoch 2 Batch 1200 Loss 0.4624\n",
            "Epoch 2 Loss 0.6546\n",
            "Time taken for 1 epoch 175.81089973449707 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.4297\n",
            "Epoch 3 Batch 100 Loss 0.4135\n",
            "Epoch 3 Batch 200 Loss 0.4323\n",
            "Epoch 3 Batch 300 Loss 0.4354\n",
            "Epoch 3 Batch 400 Loss 0.3912\n",
            "Epoch 3 Batch 500 Loss 0.4046\n",
            "Epoch 3 Batch 600 Loss 0.3915\n",
            "Epoch 3 Batch 700 Loss 0.4226\n",
            "Epoch 3 Batch 800 Loss 0.4251\n",
            "Epoch 3 Batch 900 Loss 0.4557\n",
            "Epoch 3 Batch 1000 Loss 0.3664\n",
            "Epoch 3 Batch 1100 Loss 0.4225\n",
            "Epoch 3 Batch 1200 Loss 0.3604\n",
            "Epoch 3 Loss 0.4037\n",
            "Time taken for 1 epoch 175.38477563858032 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.1975\n",
            "Epoch 4 Batch 100 Loss 0.2872\n",
            "Epoch 4 Batch 200 Loss 0.2379\n",
            "Epoch 4 Batch 300 Loss 0.2205\n",
            "Epoch 4 Batch 400 Loss 0.3367\n",
            "Epoch 4 Batch 500 Loss 0.3150\n",
            "Epoch 4 Batch 600 Loss 0.2852\n",
            "Epoch 4 Batch 700 Loss 0.2813\n",
            "Epoch 4 Batch 800 Loss 0.3373\n",
            "Epoch 4 Batch 900 Loss 0.2698\n",
            "Epoch 4 Batch 1000 Loss 0.2890\n",
            "Epoch 4 Batch 1100 Loss 0.2444\n",
            "Epoch 4 Batch 1200 Loss 0.3004\n",
            "Epoch 4 Loss 0.2813\n",
            "Time taken for 1 epoch 177.6362977027893 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1696\n",
            "Epoch 5 Batch 100 Loss 0.1698\n",
            "Epoch 5 Batch 200 Loss 0.1845\n",
            "Epoch 5 Batch 300 Loss 0.1775\n",
            "Epoch 5 Batch 400 Loss 0.1871\n",
            "Epoch 5 Batch 500 Loss 0.2292\n",
            "Epoch 5 Batch 600 Loss 0.2176\n",
            "Epoch 5 Batch 700 Loss 0.2397\n",
            "Epoch 5 Batch 800 Loss 0.2627\n",
            "Epoch 5 Batch 900 Loss 0.1838\n",
            "Epoch 5 Batch 1000 Loss 0.2504\n",
            "Epoch 5 Batch 1100 Loss 0.2492\n",
            "Epoch 5 Batch 1200 Loss 0.2185\n",
            "Epoch 5 Loss 0.2119\n",
            "Time taken for 1 epoch 175.33734560012817 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1577\n",
            "Epoch 6 Batch 100 Loss 0.1584\n",
            "Epoch 6 Batch 200 Loss 0.1108\n",
            "Epoch 6 Batch 300 Loss 0.1129\n",
            "Epoch 6 Batch 400 Loss 0.1676\n",
            "Epoch 6 Batch 500 Loss 0.1580\n",
            "Epoch 6 Batch 600 Loss 0.1472\n",
            "Epoch 6 Batch 700 Loss 0.1569\n",
            "Epoch 6 Batch 800 Loss 0.1839\n",
            "Epoch 6 Batch 900 Loss 0.2467\n",
            "Epoch 6 Batch 1000 Loss 0.1882\n",
            "Epoch 6 Batch 1100 Loss 0.1858\n",
            "Epoch 6 Batch 1200 Loss 0.1944\n",
            "Epoch 6 Loss 0.1704\n",
            "Time taken for 1 epoch 175.1591637134552 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0978\n",
            "Epoch 7 Batch 100 Loss 0.1095\n",
            "Epoch 7 Batch 200 Loss 0.1265\n",
            "Epoch 7 Batch 300 Loss 0.1208\n",
            "Epoch 7 Batch 400 Loss 0.1549\n",
            "Epoch 7 Batch 500 Loss 0.1463\n",
            "Epoch 7 Batch 600 Loss 0.1447\n",
            "Epoch 7 Batch 700 Loss 0.1463\n",
            "Epoch 7 Batch 800 Loss 0.1668\n",
            "Epoch 7 Batch 900 Loss 0.1576\n",
            "Epoch 7 Batch 1000 Loss 0.1839\n",
            "Epoch 7 Batch 1100 Loss 0.1619\n",
            "Epoch 7 Batch 1200 Loss 0.2206\n",
            "Epoch 7 Loss 0.1422\n",
            "Time taken for 1 epoch 172.9068706035614 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0901\n",
            "Epoch 8 Batch 100 Loss 0.1237\n",
            "Epoch 8 Batch 200 Loss 0.0992\n",
            "Epoch 8 Batch 300 Loss 0.0817\n",
            "Epoch 8 Batch 400 Loss 0.1168\n",
            "Epoch 8 Batch 500 Loss 0.1209\n",
            "Epoch 8 Batch 600 Loss 0.1116\n",
            "Epoch 8 Batch 700 Loss 0.1126\n",
            "Epoch 8 Batch 800 Loss 0.1473\n",
            "Epoch 8 Batch 900 Loss 0.1455\n",
            "Epoch 8 Batch 1000 Loss 0.1066\n",
            "Epoch 8 Batch 1100 Loss 0.1447\n",
            "Epoch 8 Batch 1200 Loss 0.1121\n",
            "Epoch 8 Loss 0.1220\n",
            "Time taken for 1 epoch 173.64110136032104 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1156\n",
            "Epoch 9 Batch 100 Loss 0.0821\n",
            "Epoch 9 Batch 200 Loss 0.0673\n",
            "Epoch 9 Batch 300 Loss 0.0999\n",
            "Epoch 9 Batch 400 Loss 0.1004\n",
            "Epoch 9 Batch 500 Loss 0.0928\n",
            "Epoch 9 Batch 600 Loss 0.1202\n",
            "Epoch 9 Batch 700 Loss 0.1250\n",
            "Epoch 9 Batch 800 Loss 0.1103\n",
            "Epoch 9 Batch 900 Loss 0.1047\n",
            "Epoch 9 Batch 1000 Loss 0.1174\n",
            "Epoch 9 Batch 1100 Loss 0.1272\n",
            "Epoch 9 Batch 1200 Loss 0.1304\n",
            "Epoch 9 Loss 0.1087\n",
            "Time taken for 1 epoch 171.50957942008972 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0886\n",
            "Epoch 10 Batch 100 Loss 0.0701\n",
            "Epoch 10 Batch 200 Loss 0.0967\n",
            "Epoch 10 Batch 300 Loss 0.0824\n",
            "Epoch 10 Batch 400 Loss 0.0764\n",
            "Epoch 10 Batch 500 Loss 0.1064\n",
            "Epoch 10 Batch 600 Loss 0.0939\n",
            "Epoch 10 Batch 700 Loss 0.1156\n",
            "Epoch 10 Batch 800 Loss 0.1078\n",
            "Epoch 10 Batch 900 Loss 0.1068\n",
            "Epoch 10 Batch 1000 Loss 0.1115\n",
            "Epoch 10 Batch 1100 Loss 0.1132\n",
            "Epoch 10 Batch 1200 Loss 0.1452\n",
            "Epoch 10 Loss 0.0990\n",
            "Time taken for 1 epoch 172.83899116516113 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX63nQ7n3Jk-"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "The evaluate function is similar to the training loop, except we don't use teacher forcing here. \n",
        "\n",
        "* The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
        "* Stop predicting when the model predicts the end token and store the attention weights for every time step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yooeFKDW3bGp"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSKxnZzW3erl"
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26E-3Rxi3h2g"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI9qCvkw3luM"
      },
      "source": [
        "# Testing\n",
        "\n",
        "Finally, in this section, we'll load the latest model checkpoint and test the model on a new sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrrc9khr30o8",
        "outputId": "dee9c90f-3989-45e4-a76e-2b06b2ea40a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f12b5b88fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OAu8YGU342S",
        "outputId": "e2fe1416-a4ab-454b-9178-1c92ab117272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "translate(u\"The king is life\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> the king is life <end>\n",
            "Predicted translation: der konig ist leben . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLWOlseO5V71"
      },
      "source": [
        "# Conclusion.\n",
        "\n",
        "Well, the model doesn't perform as well as Google's NMT but it's a good start."
      ]
    }
  ]
}